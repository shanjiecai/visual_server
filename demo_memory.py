#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è§†è§‰è®°å¿†æå–æ¼”ç¤ºç¨‹åº

è¯¥ç¨‹åºå®ç°äº†ä»¥ä¸‹åŠŸèƒ½ï¼š
1. æ•è·æ‘„åƒå¤´çš„è§†é¢‘å¸§
2. é€šè¿‡ç›¸ä¼¼å¸§è¿‡æ»¤å™¨å»é™¤é‡å¤å¸§
3. å°†è¿‡æ»¤åçš„å¸§å‘é€åˆ°Kafkaé˜Ÿåˆ—ï¼Œå¹¶æºå¸¦è®°å¿†æå–ä»»åŠ¡é…ç½®
4. VLM Workeræ¶ˆè´¹é˜Ÿåˆ—è¿›è¡Œè®°å¿†æå–å’Œå­˜å‚¨
5. æä¾›è®°å¿†æŸ¥è¯¢APIæœåŠ¡

æ¶æ„æµç¨‹ï¼š
æ‘„åƒå¤´ -> ç›¸ä¼¼å¸§è¿‡æ»¤ -> é˜Ÿåˆ—(æºå¸¦ä»»åŠ¡é…ç½®) -> VLM Worker(è®°å¿†æå–) -> è®°å¿†å­˜å‚¨ -> APIæŸ¥è¯¢

ç”¨æ³•:
    python demo_memory.py [--config CONFIG_PATH]
    python demo_memory.py --camera-index 0 --camera-fps 1.0

ä½œè€…ï¼šVisual Processing Team
"""

import asyncio
import argparse
import os
import signal
import sys
import yaml
import time
from pathlib import Path
from typing import Dict, Any, Optional
from loguru import logger

from producer.camera_source import CameraVideoSource
from preprocessor.similar_frame_filter import SimilarFrameFilterProcessor
from message_queue.kafka_queue import KafkaQueue
from core.pipeline import PipelineManager
from app.memory_router import create_memory_api_service


async def initialize_memory_components(config: Dict[str, Any]) -> Dict[str, Any]:
    """åˆå§‹åŒ–è®°å¿†æå–ç›¸å…³ç»„ä»¶"""
    # åˆå§‹åŒ–æ‘„åƒå¤´æº
    camera_config = config.get("camera", {})
    camera_source = CameraVideoSource(
        camera_index=camera_config.get("camera_index", 0),
        fps=camera_config.get("fps", 1.0),
    )
    await camera_source.initialize()
    logger.info(f"æ‘„åƒå¤´åˆå§‹åŒ–å®Œæˆ: index={camera_config.get('camera_index', 0)}, fps={camera_config.get('fps', 1.0)}")

    # åˆå§‹åŒ–ç›¸ä¼¼å¸§è¿‡æ»¤å™¨
    similar_frame_config = config.get("preprocessors", {}).get("similar_frame_filter", {})
    similar_frame_filter = SimilarFrameFilterProcessor(config=similar_frame_config)
    await similar_frame_filter.initialize()
    logger.info("ç›¸ä¼¼å¸§è¿‡æ»¤å™¨åˆå§‹åŒ–å®Œæˆ")

    # åˆå§‹åŒ–Kafkaé˜Ÿåˆ—
    queue = config.get("queue", {})
    if queue.get("type") == "kafka":
        kafka_queue = KafkaQueue(config=queue.get("config", {}))
        await kafka_queue.initialize()
        logger.info(f"Kafkaé˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆ: topic={queue.get('config', {}).get('topic_name', 'visual_memory')}")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„é˜Ÿåˆ—ç±»å‹: {queue.get('type')}")

    # åˆ›å»ºæµæ°´çº¿
    pipeline_manager = PipelineManager()
    pipeline = pipeline_manager.create_pipeline("memory_pipeline")
    
    # æ·»åŠ ç›¸ä¼¼å¸§è¿‡æ»¤å™¨
    pipeline.add_processor(similar_frame_filter)
    
    # è®¾ç½®è¾“å‡ºé˜Ÿåˆ—
    pipeline.set_output_queue(kafka_queue)
    
    # è®¾ç½®ä»»åŠ¡é…ç½®ï¼ˆä¼ é€’ç»™é˜Ÿåˆ—æ¶ˆæ¯ï¼‰
    task_config = _create_memory_task_config(config)
    pipeline.set_postprocessor_config(task_config)
    
    logger.info("è®°å¿†æå–æµæ°´çº¿åˆ›å»ºå®Œæˆ")

    # åˆå§‹åŒ–è®°å¿†APIæœåŠ¡ï¼ˆä»…ç”¨äºé…ç½®ï¼‰
    memory_api_service = None
    if config.get("memory_api", {}).get("enabled", False):
        api_config = config.get("memory_api", {})
        memory_api_service = create_memory_api_service(api_config)
        await memory_api_service.initialize()
        logger.info("è®°å¿†æŸ¥è¯¢APIæœåŠ¡é…ç½®å®Œæˆ")

    return {
        "camera_source": camera_source,
        "pipeline_manager": pipeline_manager,
        "kafka_queue": kafka_queue,
        "memory_api_service": memory_api_service
    }


def _create_memory_task_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ›å»ºè®°å¿†æå–ä»»åŠ¡é…ç½®"""
    # ä»é…ç½®æ–‡ä»¶ä¸­è·å–VLMä»»åŠ¡é…ç½®
    vlm_tasks = config.get("vlm_tasks", {})
    memory_config = config.get("memory_extraction", {})
    
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰vlm_tasksï¼Œç›´æ¥ä½¿ç”¨
    if vlm_tasks:
        # é€‰æ‹©è®°å¿†æ£€æµ‹ä»»åŠ¡é…ç½®
        task_config = vlm_tasks.get("memory_detection", {})
        
        # å¦‚æœæ²¡æœ‰memory_detectionä»»åŠ¡ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä»»åŠ¡
        if not task_config and vlm_tasks:
            first_task_key = list(vlm_tasks.keys())[0]
            task_config = vlm_tasks[first_task_key]
            logger.warning(f"æœªæ‰¾åˆ°memory_detectionä»»åŠ¡é…ç½®ï¼Œä½¿ç”¨ {first_task_key}")
        
        vlm_task_config = {
            "memory_detection": task_config
        }
    else:
        # å…œåº•ï¼šä½¿ç”¨åŸæœ‰çš„é…ç½®æ–¹å¼
        vlm_task_config = {
            "memory_detection": {
                "task_type": "memory_detection",
                "system_prompt": memory_config.get("detection_system_prompt", _get_default_detection_prompt(memory_config)),
                "user_prompt": "è¯·è¯†åˆ«å›¾åƒä¸­çš„æ‰€æœ‰ç‰©ä½“ç±»åˆ«ï¼Œåªè¿”å›ç±»åˆ«åç§°åˆ—è¡¨ï¼Œç”¨ä¸­æ–‡é€—å·åˆ†éš”ã€‚",
                "vlm_config": {
                    "model": "Qwen2.5-VL-72B-Instruct-AWQ",
                    "max_tokens": memory_config.get("vlm_max_tokens", 64),
                    "temperature": 0.1,
                    "base_url": "http://cc.komect.com/llm/vlgroup/",
                    "api_key": "EMPTY"
                }
            }
        }
    
    # åå¤„ç†å™¨é…ç½®ï¼ŒåŒ…å«è®°å¿†å­˜å‚¨
    postprocessor_config = {
        "memory_storage": {
            "enabled": True,
            "processor_type": "memory_storage",
            "memory_storage": memory_config.get("memory_storage", {}),
            "target_objects": memory_config.get("target_objects", [
                "æ‰‹æœº", "æ¡Œå­", "ç”µè„‘", "ç¬”", "æ°´æ¯", "åœ°æ¿", "æ¤…å­", "èŠ±", "äºº"
            ])
        }
    }
    
    return {
        "vlm_task_config": vlm_task_config,
        "postprocessor_config": postprocessor_config
    }


def _get_default_detection_prompt(config: Dict[str, Any]) -> str:
    """è·å–é»˜è®¤çš„ç‰©ä½“æ£€æµ‹æç¤ºè¯"""
    target_objects = config.get("target_objects", [
        "æ‰‹æœº", "æ¡Œå­", "ç”µè„‘", "ç¬”", "æ°´æ¯", "åœ°æ¿", "æ¤…å­", "èŠ±", "äºº"
    ])
    target_objects_str = ", ".join(target_objects)
    
    return f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è®¡ç®—æœºè§†è§‰ä¸“å®¶ï¼Œæ“…é•¿ç›®æ ‡æ£€æµ‹å’Œç‰©ä½“è¯†åˆ«ã€‚è¯·å¯¹æä¾›çš„å›¾åƒè¿›è¡Œå…¨é¢çš„ç›®æ ‡æ£€æµ‹ï¼Œè¯†åˆ«å‡ºå›¾åƒä¸­çš„æ‰€æœ‰ç‰©ä½“ã€‚

è¾“å‡ºç±»åˆ«ä»…é™äºä»¥ä¸‹ç‰©ä½“ç±»åˆ«ä¸­çš„ä¸€ç§æˆ–å¤šç§ï¼š{target_objects_str}

è¦æ±‚ï¼š
1. åªè¿”å›åœ¨å›¾åƒä¸­çœŸå®å­˜åœ¨çš„ç‰©ä½“ç±»åˆ«
2. ç”¨ä¸­æ–‡é€—å·åˆ†éš”å¤šä¸ªç±»åˆ«
3. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æè¿°
4. ä¸å…è®¸å‡ºç°ä¸åœ¨æŒ‡å®šç±»åˆ«åˆ—è¡¨ä¸­çš„ç‰©ä½“åç§°

ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼šæ°´æ¯,æ¡Œå­,æ‰‹æœº"""


async def run_memory_demo(config: Dict[str, Any]) -> None:
    """è¿è¡Œè®°å¿†æå–ä¸»æµç¨‹"""
    components = await initialize_memory_components(config)
    camera_source = components["camera_source"]
    pipeline_manager: PipelineManager = components["pipeline_manager"]
    memory_api_service = components.get("memory_api_service")
    
    # è®¾ç½®ä¿¡å·å¤„ç†ï¼Œä¼˜é›…å…³é—­
    loop = asyncio.get_event_loop()
    
    def signal_handler():
        logger.info("æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æœåŠ¡...")
        loop.create_task(cleanup(components))
    
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, signal_handler)
    
    try:
        # æç¤ºç”¨æˆ·å¯åŠ¨APIæœåŠ¡
        if config.get("memory_api", {}).get("enabled", False):
            logger.info("="*80)
            logger.info("ğŸŒ è®°å¿†æŸ¥è¯¢APIæœåŠ¡è¯´æ˜:")
            logger.info("   è®°å¿†APIå·²é›†æˆåˆ°ä¸»FastAPIåº”ç”¨ä¸­")
            logger.info("   è¯·å•ç‹¬å¯åŠ¨APIæœåŠ¡:")
            logger.info("   python server.py")
            logger.info("   ç„¶åè®¿é—®: http://localhost:8000/memory/stats")
            logger.info("   APIæ–‡æ¡£: http://localhost:8000/docs")
            logger.info("="*80)
        
        # å¯åŠ¨æµæ°´çº¿
        await pipeline_manager.start_pipeline("memory_pipeline", camera_source)
        logger.info("å¼€å§‹å¤„ç†æ‘„åƒå¤´è§†é¢‘æµ -> ç›¸ä¼¼å¸§è¿‡æ»¤ -> é˜Ÿåˆ—(æºå¸¦ä»»åŠ¡é…ç½®) -> VLM Worker")
        
        # å®šæœŸæ‰“å°ç»Ÿè®¡ä¿¡æ¯
        stats_interval = config.get("demo", {}).get("stats_interval", 30)
        last_stats_time = time.time()
        
        # ä¿æŒç¨‹åºè¿è¡Œ
        while True:
            current_time = time.time()
            
            # å®šæœŸæ‰“å°ç»Ÿè®¡ä¿¡æ¯
            if current_time - last_stats_time >= stats_interval:
                try:
                    # è·å–æµæ°´çº¿ç»Ÿè®¡
                    pipeline_status = pipeline_manager.get_pipeline_status()
                    if pipeline_status:
                        logger.info(f"æµæ°´çº¿çŠ¶æ€: {pipeline_status}")
                    
                    # è·å–é˜Ÿåˆ—ç»Ÿè®¡
                    if hasattr(components["kafka_queue"], "get_stats"):
                        queue_stats = components["kafka_queue"].get_stats()
                        logger.info(f"é˜Ÿåˆ—ç»Ÿè®¡: {queue_stats}")
                    
                    # è·å–è®°å¿†ç»Ÿè®¡ï¼ˆå¦‚æœAPIæœåŠ¡å¯ç”¨ï¼‰
                    if memory_api_service and hasattr(memory_api_service, "get_memory_storage"):
                        try:
                            memory_storage = memory_api_service.get_memory_storage()
                            if memory_storage and hasattr(memory_storage, "get_memory_stats"):
                                memory_stats = memory_storage.get_memory_stats()
                                logger.info(f"è®°å¿†ç»Ÿè®¡: {memory_stats}")
                        except Exception as e:
                            logger.debug(f"è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {e}")
                    
                    last_stats_time = current_time
                    
                except Exception as e:
                    logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            
            await asyncio.sleep(1)
            
    except Exception as e:
        logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        await cleanup(components)


async def cleanup(components: Dict[str, Any]) -> None:
    """æ¸…ç†æ‰€æœ‰ç»„ä»¶èµ„æº"""
    logger.info("æ­£åœ¨æ¸…ç†èµ„æº...")
    
    # åœæ­¢æµæ°´çº¿
    pipeline_manager = components.get("pipeline_manager")
    if pipeline_manager:
        await pipeline_manager.stop_pipeline("memory_pipeline")
    
    # å…³é—­æ‘„åƒå¤´
    camera_source = components.get("camera_source")
    if camera_source:
        await camera_source.close()
    
    # å…³é—­Kafkaé˜Ÿåˆ—
    kafka_queue = components.get("kafka_queue")
    if kafka_queue:
        await kafka_queue.close()
    
    logger.info("èµ„æºæ¸…ç†å®Œæˆ")


def load_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if not config_path:
        raise ValueError("å¿…é¡»æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„")
    
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    except Exception as e:
        raise RuntimeError(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    # ç¯å¢ƒå˜é‡è¦†ç›–
    if os.getenv("CAMERA_INDEX") and "camera" in config:
        config["camera"]["camera_index"] = int(os.getenv("CAMERA_INDEX"))
    if os.getenv("CAMERA_FPS") and "camera" in config:
        config["camera"]["fps"] = float(os.getenv("CAMERA_FPS"))
    if os.getenv("KAFKA_HOST") and os.getenv("KAFKA_PORT") and "queue" in config:
        config["queue"]["config"]["bootstrap_servers"] = [f"{os.getenv('KAFKA_HOST')}:{os.getenv('KAFKA_PORT')}"]
    if os.getenv("KAFKA_TOPIC") and "queue" in config:
        config["queue"]["config"]["topic_name"] = os.getenv("KAFKA_TOPIC")
    
    return config


def setup_logging() -> None:
    """è®¾ç½®æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stderr,
        format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    
    # æ·»åŠ æ–‡ä»¶æ—¥å¿—
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    logger.add(
        log_dir / "memory_demo.log",
        rotation="10 MB",
        retention="7 days",
        format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
        level="DEBUG"
    )


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="è§†è§‰è®°å¿†æå–æ¼”ç¤ºç¨‹åº")
    parser.add_argument("--config", type=str, help="é…ç½®æ–‡ä»¶è·¯å¾„", default="./configs/memory_demo_config.yaml")
    parser.add_argument("--camera-index", type=int, help="æ‘„åƒå¤´ç´¢å¼•")
    parser.add_argument("--camera-fps", type=float, help="æ‘„åƒå¤´FPS")
    return parser.parse_args()


async def main() -> None:
    """ä¸»å‡½æ•°"""
    setup_logging()
    args = parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.camera_index is not None:
        config["camera"]["camera_index"] = args.camera_index
    if args.camera_fps is not None:
        config["camera"]["fps"] = args.camera_fps
    
    logger.info("å¯åŠ¨è§†è§‰è®°å¿†æå–æ¼”ç¤ºç¨‹åº")
    logger.info("æ¶æ„: æ‘„åƒå¤´ -> ç›¸ä¼¼å¸§è¿‡æ»¤ -> Kafkaé˜Ÿåˆ—(æºå¸¦ä»»åŠ¡é…ç½®) -> VLM Worker(è®°å¿†æå–)")
    logger.info(f"é…ç½®: {config}")
    
    # è¿è¡Œä¸»ç¨‹åº
    await run_memory_demo(config)


if __name__ == "__main__":
    
    asyncio.run(main())
