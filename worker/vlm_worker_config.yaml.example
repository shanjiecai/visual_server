worker:
  worker_id: "vlm_worker_simple"
  poll_interval: 1
  batch_size: 1
  max_retries: 3

queue_config:
  # bootstrap_servers: ["localhost:9092"]  # Kafka服务器地址
  bootstrap_servers: ["36.137.208.165:5092"]  # 测试环境地址
  topic_name: "demo"  # 主题名称
  consumer_group: "vlm_workers"  # 消费者组
  use_kafka: true  # 是否使用Kafka（false则使用内存队列）
  max_request_size: 10485760  # 10MB，最大请求大小
  timeout_default: 30.0  # 默认超时时间（秒）
  serialize_messages: true  # 是否序列化消息

vlm_config:
  # 使用阿里云通义千问VL（需要API密钥）
  base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
  api_key: "YOUR_API_KEY_HERE"  # 请替换为实际的API密钥
  model_name: "qwen-vl-plus"
  max_tokens: 256
  temperature: 0.7
  timeout: 30.0

  default_system_prompt: |
    你是一个友好的AI助手，能够分析图像并用中文回答问题。
    请保持回答简洁友好。

logging:
  level: "INFO"
  file_path: "logs/vlm_worker.log"
  console_output: true

# 运行: python -m worker.vlm_worker --config worker/vlm_worker_config.simple.yaml